from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from datetime import datetime

def get_userInput():
    story_content = input("è¯·è¾“å…¥æ•…äº‹ä¸»äºº: ")
    story_style = input("è¯·è¾“å…¥æ•…äº‹é£æ ¼: ")
    return story_content, story_style


# ã€Caseã€‘ç›´æ¥è¾“å…¥ä¸¤ä¸ªé€‰é¡¹ä¾¿ç”Ÿæˆ _______________________________________________________________________________________________________
def run_llm(stories_content: str, stories_style: str) -> str:
    llm = OpenAI()
    
    
    # ğŸ‘‡ã€æç¤ºè¯æ¨¡æ¿æ„å»ºæ–¹å¼ä¸€ã€‘æ„å»ºä¸€ä¸ªåŒ…å«å¤šä¸ªæç¤ºè¯çš„æç¤ºè¯æ¨¡æ¿ æœ€ç»ˆè¦ä¼ ç»™ chain!! â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    multiple_input_prompt = PromptTemplate(
        template="ç»™æˆ‘è®²ä¸ªå…³äº{content_placeholder}çš„{style_placeholder}é£æ ¼çš„æ•…äº‹, 50 å­—",
		input_variables=["content_placeholder", "style_placeholder"]
	)
    multiple_input_prompt.format(content_placeholder=stories_content, style_placeholder=stories_style) # æŠŠç”¨æˆ·çš„è¾“å…¥è¿›è¡Œæ ¼å¼åŒ–
    
	# âš¡ï¸ æŠŠæ ¼å¼åŒ–åçš„å†…å®¹è¿›è¡Œå®ä¾‹åŒ–
    chain = LLMChain(llm=llm, prompt=multiple_input_prompt) 
    
     
    # ğŸ‘‡ã€æç¤ºè¯æ¨¡æ¿æ„å»ºæ–¹å¼äºŒã€‘, ä½¿ç”¨ from_template æ–¹æ³• â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
    # template = "ç»™æˆ‘è®²ä¸ªå…³äº{content_placeholder}çš„{style_placeholder}é£æ ¼çš„æ•…äº‹, 50 å­—"
    # prompt_template = PromptTemplate.from_template(template)
    # prompt_template.format(content_placeholder=stories_content, style_placeholder=stories_style)
    
    # # âš¡ï¸ æŠŠæ ¼å¼åŒ–åçš„å†…å®¹è¿›è¡Œå®ä¾‹åŒ–
    # chain = LLMChain(llm=llm, prompt=prompt_template)
    

	# ğŸŒŸ ä»¥ã€å­—å…¸å½¢å¼ã€‘å°†æ ¼å¼åŒ–çš„æç¤ºä½œä¸ºå‚æ•°ä¼ é€’ç»™ run æ–¹æ³•
    res = chain.run({ # ğŸŒŸæ”¾å…¥ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
        "content_placeholder": stories_content, 
        "style_placeholder": stories_style
	})
    return res




# ã€Caseã€‘è¾“å…¥ä¸€ä¸ªæç¤ºè¯, ç”Ÿæˆä¸€ä¸ªæ¨¡æ¿, ç”Ÿæˆå¦ä¸€ä¸ªå®Œæ•´çš„è¯­å¥ ______________________________________________________
def get_date_time(): # è·å¾—å½“å‰æ—¶é—´ => æŸä¸ªæç¤ºè¯å‚æ•°å¯ä»¥é€šè¿‡å‡½æ•°è·å¾—
    now_time = datetime.now()
    return now_time.strftime("%m/%d/%Y, %H:%M:%S")


def run_llm2(date_time) -> str:
    llm = OpenAI()
    
    prompt = PromptTemplate(
		template="å‘Šè¯‰æˆ‘{city}åœ¨{year}å¹´{date}çš„å¹³å‡æ°”æ¸©",
		input_variables=["city", "year", "date"]
	)
    partial_prompt = prompt.partial(city="HongKong", year="1998") # ğŸ”¥ ç”Ÿæˆäº†ä¸€ä¸ªæ–°çš„æç¤ºè¯æ¨¡æ¿! æœ‰äº† Hongkong çš„å˜é‡
    partial_prompt.format(date=date_time) # ğŸ”¥ è¾“å…¥æ—¶é—´, æœ€ç»ˆç”Ÿæˆ
    chain = LLMChain(llm=llm, prompt=partial_prompt)
    print(f"å®Œæ•´æç¤ºè¯: {partial_prompt}")
    res = chain.run(date_time)
    return res
    

if __name__ == "__main__":
    # Case 1 - ç”Ÿæˆæ•…äº‹:
    # story_content, story_style = get_userInput()
    # res = run_llm(story_content, story_style)
    
    # Case 2 - è·å¾—å¤©æ°”:
    now_time = get_date_time()
    res = run_llm2(now_time)
    print(res)