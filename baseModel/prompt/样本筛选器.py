from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate, FewShotPromptTemplate
from langchain.chains import LLMChain
from langchain.prompts.example_selector import SemanticSimilarityExampleSelector
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma


"""
	æ ·æœ¬é€‰æ‹©å™¨
		WHY?
			å½“æ ·æœ¬æ•°é‡éå¸¸å¤šçš„æ—¶å€™, æˆ‘ä»¬å¯ä»¥é€šè¿‡æ ·æœ¬é€‰æ‹©å™¨æ¥é€‰æ‹©ä¸€éƒ¨åˆ†æ ·æœ¬, è¿™æ ·å¯ä»¥æé«˜æ¨¡å‹çš„æ•ˆç‡
			ç¼©çŸ­å‘é€ç»™å¤§æ¨¡å‹çš„æç¤ºè¯çš„æ•°é‡, æ›´çœé’±
		HOW?
			SemanticSimilarityExampleSelector è¯­ä¹‰ç›¸ä¼¼åº¦ç­›é€‰å™¨
"""

EXAMPLES = [
	{"question": "ä½ å¥½å—?", "answer": "å½“ç„¶!æˆ‘å¾ˆå¥½!"},
    {"question": "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·?", "answer": "å¤©æ°”å¾ˆä¸é”™!"},
    {"question": "ä»Šå¤©çš„é£Ÿç‰©æ€ä¹ˆæ ·?", "answer": "é£Ÿç‰©å¾ˆç¾å‘³!"},
    {"question": "ä½ ä¼šè¯´è‹±è¯­å—?", "answer": "æ˜¯çš„ï¼Œæˆ‘å¯ä»¥å›ç­”è‹±è¯­é—®é¢˜ã€‚"},
    {"question": "å¦‚ä½•è§£å†³æ•°å­¦é¢˜?", "answer": "æˆ‘å¯ä»¥å°è¯•å¸®ä½ è§£å†³æ•°å­¦é—®é¢˜ã€‚"},
    {"question": "ä½ èƒ½æ¨èä¸€æœ¬ä¹¦å—?", "answer": "å½“ç„¶ï¼Œæˆ‘æ¨èã€Šå“ˆåˆ©Â·æ³¢ç‰¹ã€‹ç³»åˆ—ã€‚"},
    {"question": "ä»Šå¤©æœ‰ä»€ä¹ˆæ–°é—»?", "answer": "æˆ‘æ— æ³•æä¾›æœ€æ–°æ–°é—»ï¼Œä½†å¯ä»¥è®¨è®ºè¿‘æœŸçš„çƒ­ç‚¹è¯é¢˜ã€‚"},
]


def get_user_input():
	input_content = input("è¯·è¾“å…¥é—®é¢˜: ")
	return input_content


def run_llm(input_content):
    llm = OpenAI()
    
    example_prompt = PromptTemplate(
		input_variables=["question", "answer"],
		template="Question: {question}\n{answer}" # ğŸ”¥ç›¸å½“äºåˆ©ç”¨ä¸Šé¢ EXAMPLES çš„æ•°æ®è¿›è¡Œæ ¼å¼åŒ–
	)
    

    example_selector = SemanticSimilarityExampleSelector.from_examples( # ğŸ‘ˆ è¯­ä¹‰ç›¸ä¼¼åº¦ç­›é€‰å™¨
  		examples=EXAMPLES, # OpenAIEmbeddings(), # The embedding class used to produce embeddings which are used to measure semantic similarity.
        embedding_model=OpenAIEmbeddings(), # Chroma, # The VectorStore class that is used to store the embeddings and do a similarity search over.
        vector_store_class=Chroma, # å‘é‡æ•°æ®åº“å’Œæœç´¢åº“, ç”¨äºå‚¨å­˜å’Œç®¡ç† OpenAIEmbeddings ç”Ÿæˆçš„å‘é‡
        k=3  # é€‰æ‹©æœ€ç›¸ä¼¼çš„3ä¸ªç¤ºä¾‹
	)
    
    prompt = FewShotPromptTemplate(
		examples = EXAMPLES,
		example_prompt = example_prompt,
		suffix="Question: {input}", # ğŸ”¥ ä»¥ {input} ä½œä¸ºé—®é¢˜çš„è¾“å…¥
		input_variables=["input"],
  		example_selector=example_selector, # ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦é€‰æ‹©å™¨
	)

    chain = LLMChain(llm=llm, prompt=prompt)
    res = chain.run(input_content) # ğŸŒŸæ”¾å…¥ç”¨æˆ·è¾“å…¥çš„é—®é¢˜
    return res


if __name__ == "__main__":
    input_content = get_user_input()
    result = run_llm(input_content)
    print(result)
