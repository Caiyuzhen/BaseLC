"""
	WHY?
		æ¨¡å—çš„æŠ½è±¡åŒ–, é¿å…ç‰µä¸€å‘è€ŒåŠ¨å…¨èº«
			æ¯”å¦‚:
				å®šä¹‰æç¤ºè¯
				é€‰æ‹© LLM
				è¿è¡Œæ¥å£
				...
	WHAT?
		é“¾æ˜¯ä¸åŒæ¨¡å—çš„ç»„åˆ
		é“¾æ˜¯ä¸€ä¸ªæŠ½è±¡å‡ºæ¥çš„æ ‡å‡†,æé«˜äº†å¤ç”¨æ€§, ä½†ä¸ä¸€å®šè¦ç”¨é“¾æ‰èƒ½å®Œæˆè°ƒç”¨ LLM
	HOW?
		åŸºç¡€é“¾ç»“æ„
			LLM chain
			Router chain => å¤šé“¾å¹¶è¡Œç„¶åé€‰æ‹©ä¸€æ¡è¿›è¡Œå¤„ç†
			Sequential chain => å¤šé“¾ä¸²è¡Œ
		åº”ç”¨é“¾ç»“æ„å®ä¾‹
			Document chains
			Retrieval QA
"""	

# ã€ğŸŒŸ Case-å•é“¾ç»“æ„ single chain - è‡³å°‘è°ƒç”¨ä¸€æ¬¡ llm ã€‘â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
from langchain import PromptTemplate, LLMChain
from langchain.llms import OpenAI

from langchain.chains import ConversationChain
from langchain.chains.router import MultiPromptChain
from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser
from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE
from langchain.chains import SimpleSequentialChain

# llm=OpenAI()

prompt_temp = "ç»™æˆ‘ä¸€ä¸ªå°çŒ«å’ªçš„æ˜µç§°"
llm_chain = LLMChain(
	llm=llm,
	prompt=PromptTemplate.from_template(prompt_temp)
)
res1 = llm_chain.predict()
print(res1)



# ã€ğŸŒŸ Case-å¤šé“¾ç»“æ„ Multiple. chain - è‡³å°‘è°ƒç”¨ä¸¤æ¬¡ llm ã€‘â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# æ¯”å¦‚æœ‰æ–‡å­¦å®¶ã€ç¿»è¯‘ä¸“å®¶ã€æ•°å­¦å®¶ç­‰ç­‰ä¸åŒçš„ä¸“å®¶é“¾: å®šä¹‰ prompt => å®šä¹‰llm/embedding => å®šä¹‰chain(å¤šé“¾å¹¶è¡Œç„¶åé€‰æ‹©ä¸€æ¡è¿›è¡Œå¤„ç†) => è¿è¡Œ predict
# ğŸ‘‡ {input} åœ¨æ¨¡æ¿å­—ç¬¦ä¸²ä¸­ä½œä¸ºå ä½ç¬¦ä½¿ç”¨, æ¯”å¦‚ç”¨æˆ·è¾“å…¥ "è¿™åªçŒ«å«ä»€ä¹ˆå¥½ï¼Ÿ"ï¼Œé‚£ä¹ˆ {input} å°±ä¼šè¢«æ›¿æ¢ä¸º "è¿™åªçŒ«å«ä»€ä¹ˆå¥½ï¼Ÿ"
llm=OpenAI()
name_temp = """ä½ æ˜¯ä¸€ä¸ªéå¸¸æœ‰åˆ›æ„çš„èµ·åä¸“å®¶. \
    ä½ éå¸¸æ“…é•¿ç»™å°çŒ«å’ªèµ·å¥½å¬çš„ã€å¯Œå«å¯“æ„çš„åå­—. \
    ç”¨ä¸­æ–‡ç»™å‡º 3 ç§å›ç­”
    
    è¿™é‡Œæ˜¯é—®é¢˜:
    {input}
"""

tran_temp = """ä½ æ˜¯ä¸€ä¸ªéå¸¸ç²¾é€šè‹±è¯­çš„ç¿»è¯‘ä¸“å®¶. \
    ä½ éå¸¸æ“…é•¿å°†ä¸­æ–‡ç¿»è¯‘æˆè‹±æ–‡. \
	ç”¨è‹±æ–‡ç»™å‡ºä½ çš„å›ç­”
 
    è¿™é‡Œæ˜¯é—®é¢˜:
    {input}
"""


prompt_infos = [ # ğŸ”¥å®šä¹‰ Router chain éœ€è¦ç»™åˆ°è¿™éƒ¨ä»½ä¿¡æ¯
	{
		"name": "naming",
  		"description": "æ“…é•¿ç”¨ä¸­æ–‡èµ·åå­—",
    	"prompt_template": name_temp,
	},
 	{
		"name": "english",
  		"description": "æ“…é•¿å°†ä¸­æ–‡ç¿»è¯‘æˆè‹±æ–‡",
		"prompt_template": tran_temp,
	}
]

destination_chains = {} # ç”¨æ¥å­˜å‚¨ä¸åŒçš„å•é“¾

# ğŸ‘‡å¯¹æ¯æ¡å•é“¾è¿›è¡Œåˆå§‹åŒ–
for p_info in prompt_infos:
    name = p_info["name"]
    prompt_template = p_info["prompt_template"]
    prompt = PromptTemplate(
		template=prompt_template,
  		input_variables=["input"] # è¡¨ç¤ºæ¨¡æ¿ä¸­çš„ {input} ä¼šè¢«æ›¿æ¢ä¸ºç”¨æˆ·è¾“å…¥çš„å†…å®¹
	)
    chain = LLMChain(llm=llm, prompt=prompt)
    destination_chains[name] = chain # è¡¨ç¤ºå°†é“¾å­˜å‚¨åˆ° destination_chains ä¸­

default_chain = ConversationChain(llm=llm, output_key="text") # å®šä¹‰é»˜è®¤çš„é“¾



# ğŸ‘‡é…ç½® router çš„ prompt
destinations = [f"{p['name']}: {p['description']}" for p in prompt_infos] # éå† prompt_infos
destinations_str = "\n".join(destinations) # å°† destinations ç”¨æ¢è¡Œç¬¦è¿æ¥èµ·æ¥

router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str) # å°† destinations_str ä¼ å…¥åˆ°æ¨¡æ¿ä¸­ => å°±æ˜¯éå†å‡ºæ¥çš„ prompt_infos
router_prompt = PromptTemplate(
    template=router_template,
    input_variables=["input"],
    output_parser=RouterOutputParser()
)
router_chain = LLMRouterChain.from_llm(llm, router_prompt) # ç”¨ LLMRouterChain.from_llm() æ–¹æ³•åˆ›å»º router_chain


# ğŸ‘‡å°† router_chain å’Œ destination_chains ä¼ å…¥åˆ° MultiPromptChain ä¸­
chain = MultiPromptChain(
	router_chain=router_chain,
	destination_chains=destination_chains,
 	default_chain=default_chain,
  	verbose=True
)


print(chain.run("è¿™åªçŒ«å«ä»€ä¹ˆå¥½ï¼Ÿ"))
print(chain.run("è‹¹æœçš„è‹±æ–‡"))





# ã€ğŸŒŸ Case-å¤šé“¾ä¸²è¡Œç»“æ„ Multiple. chain - è‡³å°‘è°ƒç”¨ä¸¤æ¬¡ llm ã€‘â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
llm=OpenAI()
temp = """ä½ æ˜¯ä¸€ä¸ªéå¸¸æœ‰åˆ›æ„çš„èµ·åä¸“å®¶. \
    ä½ éå¸¸æ“…é•¿ç»™å°çŒ«å’ªèµ·å¯Œå«å¯“æ„çš„åå­—. \
    ç”¨ä¸­æ–‡ç»™å‡º 3 ä¸ªå›ç­”
    
    è¿™é‡Œæ˜¯é—®é¢˜:
    {input}
"""

temp = """ä½ æ˜¯ä¸€ä¸ªéå¸¸ç²¾é€šåå­—çš„è¯„è®ºå®¶. \
    ä½ éå¸¸æ“…é•¿åˆ†æåå­—çš„ä¼˜åŠ£, ç»™åå­—åšåˆ†æ. \
	åˆ¤æ–­å“ªä¸ªåå­—æ¯”è¾ƒå¥½
 
    åå­—åˆ†æ:
    {synopsis}
    å¯¹ä¸Šé¢çš„åå­—è¿›è¡Œåˆ†æ, åˆ¤æ–­å“ªä¸ªæ›´å¥½:
"""


# å®šä¹‰æ¨¡æ¿ç»“æ„-A
prompt_template = PromptTemplate(template=temp, input_variables=["input"]) # æ¨¡æ¿ä¸­çš„ {input} ä¼šè¢«æ›¿æ¢ä¸ºç”¨æˆ·è¾“å…¥çš„å†…å®¹
# å®šä¹‰é“¾ç»“æ„-A
synopsis_chain = LLMChain(llm=llm, prompt=prompt_template)

# å®šä¹‰æ¨¡æ¿ç»“æ„-B
prompt_template = PromptTemplate(template=temp, input_variables=["synopsis"])# æ¨¡æ¿ä¸­çš„ {synopsis} ä¼šè¢«æ›¿æ¢ä¸ºç”¨æˆ·è¾“å…¥çš„å†…å®¹
# å®šä¹‰é“¾ç»“æ„-B
review_chain = LLMChain(llm=llm, prompt=prompt_template)

# ç”¨æ¥å­˜å‚¨ä¸åŒçš„å•é“¾
overall_chain = SimpleSequentialChain(
	chains=[synopsis_chain, review_chain],
	verbose=True
)

review = overall_chain.run("ç»™æˆ‘ä¸€äº›å°çŒ«å’ªçš„åç§°")




# ã€ğŸŒŸ Case-æ–‡æœ¬é“¾å¤„ç† Transformation chainã€‘â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# æ¯”å¦‚åªæ˜¯æŠŠä½ çš„ prompt çš„ç¬¬ä¸€å¥è¯è·Ÿæœ€åä¸€å¥è¯æˆªå–å‡ºæ¥å‘ç»™ llm
# Stuff



# ã€ğŸŒŸ Case-é•¿æ–‡æœ¬é“¾å¤„ç† Document chain typeã€‘æ¯”å¦‚å¤„ç†å‘é‡æ•°æ®åº“å¯ä»¥ â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# æ¯”å¦‚åªæ˜¯æŠŠä½ çš„ prompt çš„ç¬¬ä¸€å¥è¯è·Ÿæœ€åä¸€å¥è¯æˆªå–å‡ºæ¥å‘ç»™ llm
# Refine
# Map reduce
# Map rerank